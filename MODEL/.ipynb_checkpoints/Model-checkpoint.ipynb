{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f014ade8",
   "metadata": {},
   "source": [
    "# **Potato Disease Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6105ab64",
   "metadata": {},
   "source": [
    "## Import Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27ff1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3312a5a",
   "metadata": {},
   "source": [
    "\n",
    "* tensorflow is imported as tf.\n",
    "* The models and layers sub-modules are imported from tensorflow.keras. These sub-modules provide functions for creating and training neural network models, as well as building and configuring different types of layers.\n",
    "* matplotlib.pyplot is imported as plt, which allows you to create different types of plots and visualizations to analyze your data.\n",
    "* IPython.display.HTML is imported to display HTML content in the Jupyter notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc3329",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f071a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c5dff",
   "metadata": {},
   "source": [
    "## Data Argumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "481c5019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32917 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset/train',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aff553",
   "metadata": {},
   "source": [
    "* This code uses the ImageDataGenerator class from tensorflow.keras.preprocessing.image module to perform data augmentation on image data during training of a deep learning model. Data augmentation helps to artificially increase the size of the dataset by creating new, slightly modified versions of the existing images, which helps to improve the robustness of the model and reduce overfitting.\n",
    "\n",
    "* The train_datagen object is created with several parameters to specify the types of image augmentations to apply, such as rotating the image by a random angle between -10 and 10 degrees, and randomly flipping the image horizontally. The rescale parameter is used to normalize the pixel values in the image to be between 0 and 1.\n",
    "\n",
    "* The train_generator object is then created using the flow_from_directory() method, which takes the path to the training directory, the target size of the images (IMAGE_SIZE x IMAGE_SIZE), the batch size, and the class mode (sparse in this case, which means that the labels are integers). The generator will read images from the directory, apply the specified augmentations, and generate batches of augmented images for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b8172c",
   "metadata": {},
   "source": [
    "## Class Names with Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8011f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple___Black_rot': 0,\n",
       " 'Apple___Cedar_apple_rust': 1,\n",
       " 'Apple___healthy': 2,\n",
       " 'Corn_(maize)___Common_rust_': 3,\n",
       " 'Corn_(maize)___Northern_Leaf_Blight': 4,\n",
       " 'Corn_(maize)___healthy': 5,\n",
       " 'Grape___Black_rot': 6,\n",
       " 'Grape___Esca_(Black_Measles)': 7,\n",
       " 'Grape___healthy': 8,\n",
       " 'Potato___Early_blight': 9,\n",
       " 'Potato___Late_blight': 10,\n",
       " 'Potato___healthy': 11,\n",
       " 'Tomato___Bacterial_spot': 12,\n",
       " 'Tomato___Early_blight': 13,\n",
       " 'Tomato___Late_blight': 14,\n",
       " 'Tomato___healthy': 15}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2cd85",
   "metadata": {},
   "source": [
    "## Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48b61f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple___Black_rot',\n",
       " 'Apple___Cedar_apple_rust',\n",
       " 'Apple___healthy',\n",
       " 'Corn_(maize)___Common_rust_',\n",
       " 'Corn_(maize)___Northern_Leaf_Blight',\n",
       " 'Corn_(maize)___healthy',\n",
       " 'Grape___Black_rot',\n",
       " 'Grape___Esca_(Black_Measles)',\n",
       " 'Grape___healthy',\n",
       " 'Potato___Early_blight',\n",
       " 'Potato___Late_blight',\n",
       " 'Potato___healthy',\n",
       " 'Tomato___Bacterial_spot',\n",
       " 'Tomato___Early_blight',\n",
       " 'Tomato___Late_blight',\n",
       " 'Tomato___healthy']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c98f22f",
   "metadata": {},
   "source": [
    "## Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e159071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15016 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'dataset/val',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a7c9d",
   "metadata": {},
   "source": [
    "* This code creates a validation generator similar to the train_generator, but for the validation set. The validation_datagen object is created with the same set of parameters as train_datagen for consistency.\n",
    "\n",
    "* The validation_generator is created using the flow_from_directory() method, which takes the path to the validation directory, the target size of the images (IMAGE_SIZE x IMAGE_SIZE), the batch size, and the class mode (sparse in this case, which means that the labels are integers). The generator will read images from the directory and generate batches of images for validation during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eae32c",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1df606de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1073 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'dataset/test',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fa68d0",
   "metadata": {},
   "source": [
    "* This code creates a test generator similar to the train_generator and validation_generator. The test_datagen object is created with the same set of parameters as train_datagen and validation_datagen for consistency.\n",
    "\n",
    "* The test_generator is created using the flow_from_directory() method, which takes the path to the test directory, the target size of the images (IMAGE_SIZE x IMAGE_SIZE), the batch size, and the class mode (sparse in this case, which means that the labels are integers). The generator will read images from the directory and generate batches of images for testing the model after training is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae35dd7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39a7c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 16\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(256, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa21f0d",
   "metadata": {},
   "source": [
    "* This code defines a convolutional neural network (CNN) model using the Sequential API from tensorflow.keras. The model architecture consists of several convolutional layers, max pooling layers, and dense layers.\n",
    "\n",
    "* The input_shape variable specifies the shape of the input tensor to the model, which is (IMAGE_SIZE, IMAGE_SIZE, CHANNELS), where IMAGE_SIZE is the target size of the input images and CHANNELS is the number of color channels in the images (3 for RGB images).\n",
    "\n",
    "* The n_classes variable specifies the number of classes in the dataset.\n",
    "\n",
    "* The model architecture consists of six convolutional layers, each followed by a max pooling layer to downsample the feature maps. The first convolutional layer has 32 filters with a 3x3 kernel size and uses the relu activation function. The remaining convolutional layers have 64 filters with a 3x3 kernel size and also use the relu activation function.\n",
    "\n",
    "* After the convolutional layers, the feature maps are flattened into a 1D array and passed through two dense layers. The first dense layer has 64 units with a relu activation function, and the second dense layer has n_classes units with a softmax activation function, which outputs a probability distribution over the classes.\n",
    "\n",
    "* This model can be used for image classification tasks on datasets with n_classes number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b7d44",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b3d8156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 127, 127, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 62, 62, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 30, 30, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 115200)            0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               14745728  \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,841,040\n",
      "Trainable params: 14,841,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9b80e",
   "metadata": {},
   "source": [
    "## Model Compile with Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f31a5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9160e9a0",
   "metadata": {},
   "source": [
    "### This code compiles the CNN model defined in the previous code block using the compile() method.\n",
    "\n",
    "* The optimizer parameter is set to 'adam', which is an optimization algorithm that is commonly used for deep learning models.\n",
    "\n",
    "* The loss parameter is set to tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), which is the loss function used to measure the difference between the predicted and actual labels. SparseCategoricalCrossentropy is used because the labels are in integer form, and not one-hot encoded.\n",
    "\n",
    "* The metrics parameter is set to 'accuracy', which specifies that the accuracy of the model will be used as the evaluation metric during training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dceef",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e76ae58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 889/1000 [=========================>....] - ETA: 1:32 - loss: 2.8816 - accuracy: 0.0678"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=1000,\n",
    "    batch_size=32,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=16,\n",
    "    verbose=1,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1054361",
   "metadata": {},
   "source": [
    "### This code trains the CNN model on the training set using the fit() method.\n",
    "\n",
    "* The train_generator and validation_generator variables are the generators that generate batches of training and validation data respectively. These generators use data augmentation techniques such as rotation and horizontal flip to increase the amount of training data and prevent overfitting.\n",
    "\n",
    "* The steps_per_epoch parameter is set to 115, which is the number of batches of samples in one epoch of training data. The batch_size parameter is set to 32, which is the number of samples in each batch.\n",
    "\n",
    "* The validation_steps parameter is set to 16, which is the number of batches of samples in one epoch of validation data.\n",
    "\n",
    "* The verbose parameter is set to 1, which specifies the verbosity mode.\n",
    "\n",
    "* The epochs parameter is set to 20, which is the number of times the model will be trained on the entire training dataset.\n",
    "\n",
    "* The training progress and evaluation metrics are stored in the history variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27387c64",
   "metadata": {},
   "source": [
    "## Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33fc858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 12s 362ms/step - loss: 0.2248 - accuracy: 0.9189\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a6913",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23e66f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dfade2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
